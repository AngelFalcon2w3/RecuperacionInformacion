{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd16efe7639ac05",
   "metadata": {},
   "source": [
    "# Ejercicio 9: Uso de la API de Google Gemini\n",
    "\n",
    "En este ejercicio vamos a aprender a utilizar la API de OpenAI\n",
    "\n",
    "## 1. Uso básico\n",
    "\n",
    "El siguiente código sirve para conectarse con la API de Google Gemini de forma básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a6608515f3af8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T15:42:17.205511Z",
     "start_time": "2025-07-02T15:42:11.198891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make predictions.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    contents=\"Explain how AI works in a few words\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a30de61bd443d1d",
   "metadata": {},
   "source": [
    "## 2. Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488be80d85df276",
   "metadata": {},
   "source": [
    "### 2.1 Cargo el corpus de 20 News Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36aa2a96f75e4a43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T15:14:54.799009Z",
     "start_time": "2025-06-30T15:14:47.902617Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroupsdocs = newsgroups.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51d3685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>\\nNot in isolated ground recepticles (usually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      \\n\\nI am sure some bashers of Pens fans are pr...\n",
       "1      My brother is in the market for a high-perform...\n",
       "2      \\n\\n\\n\\n\\tFinally you said what you dream abou...\n",
       "3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...\n",
       "4      1)    I have an old Jasmine drive which I cann...\n",
       "...                                                  ...\n",
       "18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...\n",
       "18842  \\nNot in isolated ground recepticles (usually ...\n",
       "18843  I just installed a DX2-66 CPU in a clone mothe...\n",
       "18844  \\nWouldn't this require a hyper-sphere.  In 3-...\n",
       "18845  After a tip from Gary Crum (crum@fcom.cc.utah....\n",
       "\n",
       "[18846 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(newsgroupsdocs, columns=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167484d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>I am sure some bashers of Pens fans are pretty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>Finally you said what you dream about. Mediter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>Think! It's the SCSI card doing the DMA transf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>1) I have an old Jasmine drive which I cannot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...   \n",
       "1  My brother is in the market for a high-perform...   \n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...   \n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...   \n",
       "4  1)    I have an old Jasmine drive which I cann...   \n",
       "\n",
       "                                           text_norm  \n",
       "0  I am sure some bashers of Pens fans are pretty...  \n",
       "1  My brother is in the market for a high-perform...  \n",
       "2  Finally you said what you dream about. Mediter...  \n",
       "3  Think! It's the SCSI card doing the DMA transf...  \n",
       "4  1) I have an old Jasmine drive which I cannot ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "# Limpieza básica\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"text_norm\"] = df[\"text\"].astype(str).map(normalize_text)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16237cc6ae2f7853",
   "metadata": {},
   "source": [
    "### 2.2 Transformo a embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b271aa4b20ace0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   doc_id  chunk_id                                               text\n",
       " 0       0         0  I am sure some bashers of Pens fans are pretty...\n",
       " 1       1         0  My brother is in the market for a high-perform...\n",
       " 2       2         0  Finally you said what you dream about. Mediter...\n",
       " 3       2         1  urds and Turks once upon a time! Ohhhh so swed...\n",
       " 4       3         0  Think! It's the SCSI card doing the DMA transf...,\n",
       " 38871)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunk_text(text: str, max_chars: int = 800, overlap: int = 100):\n",
    "    \"\"\"\n",
    "    Chunking por caracteres.\n",
    "    max_chars ~ 600-1000 suele funcionar bien.\n",
    "    overlap ayuda a no cortar ideas a la mitad.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    n = len(text)\n",
    "    while start < n:\n",
    "        end = min(start + max_chars, n)\n",
    "        chunk = text[start:end]\n",
    "        chunk = chunk.strip()\n",
    "        if len(chunk) > 0:\n",
    "            chunks.append(chunk)\n",
    "        if end == n:\n",
    "            break\n",
    "        start = max(0, end - overlap)\n",
    "    return chunks\n",
    "\n",
    "records = []\n",
    "for i, row in df.iterrows():\n",
    "    chunks = chunk_text(row[\"text_norm\"], max_chars=800, overlap=100)\n",
    "    for j, ch in enumerate(chunks):\n",
    "        records.append({\n",
    "            \"doc_id\": int(i),\n",
    "            \"chunk_id\": j,\n",
    "            \"text\": ch\n",
    "        })\n",
    "\n",
    "chunks_df = pd.DataFrame(records)\n",
    "chunks_df.head(), len(chunks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939af4d8947ba81",
   "metadata": {},
   "source": [
    "### 2.3 Creo una query y hago la búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da75a5ce3c09aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "MODEL_NAME = \"intfloat/e5-base-v2\"   # recomendado para retrieval\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# Textos a indexar (pasajes)\n",
    "passages = [\"passage: \" + t for t in chunks_df[\"text\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8c18c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cb776c7cc04023be6f93968018f889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embeddings (N x D)\n",
    "# Se debe usar normalize_embeddings=True para similitud coseno\n",
    "embeddings = model.encode(\n",
    "    passages[:5000],\n",
    "    batch_size=16,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True\n",
    ").astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "469ce005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 768) float32\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape, embeddings.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "087250dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed_query(query: str) -> np.ndarray:\n",
    "    q = \"query: \" + query\n",
    "    vec = model.encode(\n",
    "        [q],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True\n",
    "    ).astype(\"float32\")\n",
    "    return vec\n",
    "\n",
    "query_text = \"My brother is in the market\"\n",
    "\n",
    "query_vec = embed_query(query_text)\n",
    "query_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b0a8f32632e705",
   "metadata": {},
   "source": [
    "Obtengo los 5 documentos más similares a mi query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0f02ff1b75a2864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Query: 'My brother is in the market'\n",
      "Top 5 documentos más similares:\n",
      "\n",
      "================================================================================\n",
      "Rank 1 (Score: 0.7779)\n",
      "Doc ID: 2205, Chunk ID: 0\n",
      "Text: I hope you're not going to flame him. Please give him the same coutesy you' ve given me....\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 2 (Score: 0.7743)\n",
      "Doc ID: 1749, Chunk ID: 0\n",
      "Text: I have the following items for sale. The highest bid for each to arrive in my email box by 5:00 pm EDT Wednesday April 21, 1993 gets the item. 1] Skillcraft Senior Chemlab Set 4581 Safe for Ages 10 an...\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 3 (Score: 0.7739)\n",
      "Doc ID: 2539, Chunk ID: 0\n",
      "Text: Well, I've been informed that the price on the whole thing I'm selling is now less than the price I'm selling it for. That will teach me to wait that long before getting rid of electronic equipment. N...\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 4 (Score: 0.7726)\n",
      "Doc ID: 1389, Chunk ID: 1\n",
      "Text: he lease... that could make it quite an attractive arrangement... Bizarre? Yes. Impossible? Not really......\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 5 (Score: 0.7718)\n",
      "Doc ID: 2286, Chunk ID: 2\n",
      "Text: unemployed Israeli who complains of being obliged to work for wages that are lower than the unemployment insurance he receives....\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculo de la similitud coseno entre la query y todos los embeddings\n",
    "similarities = np.dot(embeddings, query_vec.T).flatten()\n",
    "\n",
    "top_k = 5\n",
    "top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Query: '{query_text}'\")\n",
    "print(\"Top 5 documentos más similares:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for rank, idx in enumerate(top_indices, 1):\n",
    "    score = similarities[idx]\n",
    "    text = chunks_df.iloc[idx][\"text\"]\n",
    "    doc_id = chunks_df.iloc[idx][\"doc_id\"]\n",
    "    chunk_id = chunks_df.iloc[idx][\"chunk_id\"]\n",
    "    \n",
    "    print(f\"Rank {rank} (Score: {score:.4f})\")\n",
    "    print(f\"Doc ID: {doc_id}, Chunk ID: {chunk_id}\")\n",
    "    print(f\"Text: {text[:200]}...\")  \n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
